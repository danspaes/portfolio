{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For missing and encoding the categorical data\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#For splitting the dataset \n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#For feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "\n",
    "# First parameter mentions the lines, where the second means the columns. The -1 removes the last column\n",
    "X = dataset.iloc[:,:-1].values # For matrix of features, where is composed of independent values \n",
    "Y = dataset.iloc[:,3].values  # For dependent variable matrix, where is the value that we will predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking care of missing data\n",
    "\n",
    "### The missing data is usually changed by either mean or more frequent values, depending the context. The missing_values parameter search the missing nan values. Strategy parameter is what we are going to use to calculate and the last is to define if the strategy will be applied by rows (1 ) or by columns (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0 )\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorical Data\n",
    "# In out example the we have two categorical variables, the Country and Purchased. It is needed to encode this kind\n",
    "# of values \n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0])\n",
    "# It still has problems due to not showing the correct label since it gives numbers to \n",
    "# each value. The model will mislead to treat one value higher than another. To solve it, it is needed \n",
    "# to nomalize the data.\n",
    "\n",
    "# One for the country, which is categorized\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0]) # It is needed to inform the column index, 0 in our case\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "#One for the purchased, which will be labeled\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into training and testing sets.\n",
    "\n",
    "### The order is important, where the where the X is splited into X_train and X_test. The test_size .2 cuts 20% of the dataset as test and 80% as training it can be used the training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "### It can be done by either Standardisation or Normalisation.  On Standardisation, for each value it is subtracted the mean value and divided by the standard deviation. On Normalisation, each observation is subtracted by the minimun value and then divided by the result of the maximun value minus the minimun value of the observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
